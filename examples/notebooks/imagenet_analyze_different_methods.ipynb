{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Analyze different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the effect of the proposed methods on some recent networks. We compare the results based on a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.tests.networks.imagenet\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "eutils = imp.load_source(\"utils\", \"../utils.py\")\n",
    "imgnetutils = imp.load_source(\"utils_imagenet\", \"../utils_imagenet.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose & load image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is based on a single test image of the ones stored in `examples/images`. Other example images can be used by loading these into the above folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of an image in the example folder (between 0-6)\n",
    "image_n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full list of currently available models is available at `/innvestigate/applications/imagenet.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a list of models\n",
    "netnames = [\"vgg16\",\n",
    "            \"resnet50\",\n",
    "            \"inception_v3\",\n",
    "            \"densenet121\"]\n",
    "           \n",
    "\n",
    "n_nets = len(netnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing vgg16...\n",
      "Input (0.0201s) Gradient (0.3347s) Integrated Gradients (2.4653s) Deconvnet (0.4642s) Guided Backprop (0.1525s) PatterNet (3.9709s) Pattern Attribution (5.8157s) LRP Epsilon (0.7294s) LRP-PresetAFlat (1.0880s) LRP-PresetBFlat (1.4424s) \n",
      "Analyzing resnet50...\n",
      "Input (0.1504s) Gradient (2.3391s) Integrated Gradients (8.4948s) Deconvnet (2.9734s) Guided Backprop (2.9394s) PatterNet Analyzer not available for this model.\n",
      "Pattern Attribution Analyzer not available for this model.\n",
      "LRP Epsilon (5.2389s) LRP-PresetAFlat (7.2437s) LRP-PresetBFlat (9.2995s) \n",
      "Analyzing inception_v3...\n",
      "Input (0.2535s) Gradient (3.4629s) Integrated Gradients (18.4573s) Deconvnet (6.5985s) Guided Backprop (5.3657s) PatterNet Analyzer not available for this model.\n",
      "Pattern Attribution Analyzer not available for this model.\n",
      "LRP Epsilon (10.7862s) LRP-PresetAFlat (11.4236s) LRP-PresetBFlat (15.9015s) \n",
      "Analyzing densenet121...\n",
      "Input (0.4154s) Gradient (4.6482s) Integrated Gradients (25.3047s) Deconvnet (9.8955s) Guided Backprop (9.8620s) PatterNet Analyzer not available for this model.\n",
      "Pattern Attribution Analyzer not available for this model.\n",
      "LRP Epsilon (16.0703s) LRP-PresetAFlat "
     ]
    }
   ],
   "source": [
    "pattern_type = \"relu\"\n",
    "channels_first = keras.backend.image_data_format == \"channels_first\"\n",
    "analysis_all = []\n",
    "text = []\n",
    "\n",
    "for i, netname in enumerate(netnames):\n",
    "    print(\"Analyzing {}...\".format(netname))\n",
    "    \n",
    "    # Build model.\n",
    "    tmp = getattr(innvestigate.applications.imagenet, netname)\n",
    "    net = tmp(load_weights=True, load_patterns=pattern_type)\n",
    "    model = keras.models.Model(inputs=net[\"in\"], outputs=net[\"out\"])\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    modelp = keras.models.Model(inputs=net[\"in\"], outputs=net[\"sm_out\"])\n",
    "    modelp.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    \n",
    "    # Load image from example folder\n",
    "    images, label_to_class_name = eutils.get_imagenet_data(net[\"image_shape\"][0])\n",
    "    images = images[image_n]\n",
    "    \n",
    "    \n",
    "    color_conversion = \"BGRtoRGB\" if net[\"color_coding\"] == \"BGR\" else None\n",
    "\n",
    "    # Analysis.\n",
    "    patterns = net[\"patterns\"]\n",
    "        \n",
    "    methods = [\n",
    "        # NAME             POSTPROCESSING     TITLE\n",
    "\n",
    "        # Show input.\n",
    "        (\"input\",                 {},                            imgnetutils.image,   \"Input\"),\n",
    "\n",
    "        # Function\n",
    "        (\"gradient\",              {},                            imgnetutils.graymap, \"Gradient\"),\n",
    "        (\"integrated_gradients\",  {},                            imgnetutils.graymap, \"Integrated Gradients\"),\n",
    "\n",
    "        # Signal\n",
    "        (\"deconvnet\",             {},                            imgnetutils.bk_proj, \"Deconvnet\"),\n",
    "        (\"guided_backprop\",       {},                            imgnetutils.bk_proj, \"Guided Backprop\"),\n",
    "        (\"pattern.net\",           {\"patterns\": patterns},        imgnetutils.bk_proj, \"PatterNet\"),\n",
    "\n",
    "        # Interaction\n",
    "        (\"pattern.attribution\",   {\"patterns\": patterns},        imgnetutils.heatmap, \"Pattern Attribution\"),\n",
    "        (\"lrp.epsilon\",           {\"epsilon\": 1},                imgnetutils.heatmap, \"LRP Epsilon\"),\n",
    "        (\"lrp.sequential_preset_a_flat\", {\"epsilon\": 1},         imgnetutils.heatmap, \"LRP-PresetAFlat\"),\n",
    "        (\"lrp.sequential_preset_b_flat\", {\"epsilon\": 1},         imgnetutils.heatmap,  \"LRP-PresetBFlat\"),\n",
    "    ]\n",
    "\n",
    "    # Create analyzers.\n",
    "    analyzers = []\n",
    "    for method in methods:\n",
    "        try:\n",
    "            analyzer = innvestigate.create_analyzer(method[0],\n",
    "                                                      model,\n",
    "                                                      **method[1])\n",
    "        except innvestigate.NotAnalyzeableModelException:\n",
    "            analyzer = None\n",
    "        analyzers.append(analyzer)\n",
    "\n",
    "    # Create analysis.\n",
    "    analysis = np.zeros([len(analyzers)] + net[\"image_shape\"] + [3])\n",
    "\n",
    "    image,y = images\n",
    "    image = image[None, :, :, :]\n",
    "    # Predict label.\n",
    "    x = imgnetutils.preprocess(image, net)\n",
    "    presm = model.predict_on_batch(x)[0]\n",
    "    prob = modelp.predict_on_batch(x)[0]\n",
    "    y_hat = prob.argmax()\n",
    "    \n",
    "    # Save prediction info:\n",
    "    text.append((\"%s\" %label_to_class_name[y],       # ground truth label\n",
    "                 \"%.2f\" %presm.max(),                # pre-softmax logits\n",
    "                 \"%.2f\" % prob.max(),                # probabilistic softmax output  \n",
    "                 \"%s\" %label_to_class_name[y_hat]    # predicted label\n",
    "                ))\n",
    "\n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        # Measure execution time\n",
    "        t_start = time.time()\n",
    "        print('{} '.format(''.join(methods[aidx][-1])), end='', flush=True)\n",
    "        \n",
    "        is_input_analyzer = methods[aidx][0] == \"input\"\n",
    "        # Analyze.\n",
    "        if analyzer != None:\n",
    "            a = analyzer.analyze(image if is_input_analyzer else x)\n",
    "            t_elapsed = time.time() - t_start\n",
    "            print('({:.4f}s) '.format(t_elapsed), end='', flush=True)\n",
    "            # Postprocess.\n",
    "            if not np.all(np.isfinite(a)):\n",
    "                print(\"Image %i, analysis of %s not finite: nan %s inf %s\" %\n",
    "                      (i, methods[aidx][3],\n",
    "                       np.any(np.isnan(a)), np.any(np.isinf(a))))\n",
    "            if not is_input_analyzer:\n",
    "                a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
    "            a = methods[aidx][2](a)\n",
    "            analysis[aidx] = a[0]\n",
    "        else:\n",
    "            print(\"Analyzer not available for this model.\")\n",
    "            analysis[aidx] = np.zeros_like(image)\n",
    "    print()\n",
    "            \n",
    "    \n",
    "    # Clear session.\n",
    "    if keras.backend.backend() == 'tensorflow':\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    analysis_all.append(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analysis.\n",
    "grid = [[analysis_all[i][j] for j in range(len(methods))]\n",
    "        for i in range(n_nets)]\n",
    "label, presm, prob, pred = zip(*text)\n",
    "row_labels_left = [(n,'') for n in netnames]\n",
    "row_labels_right = [('label: {}'.format(label[i]),'pred: {}'.format(pred[i])) for i in range(len(label))]\n",
    "col_labels = [method[3] for method in methods]\n",
    "\n",
    "eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
