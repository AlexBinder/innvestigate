{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Analyze different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the effect of the proposed methods on some recent networks. We compare the results based on a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.tests.networks.imagenet\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "eutils = imp.load_source(\"utils\", \"../utils.py\")\n",
    "imgnetutils = imp.load_source(\"utils_imagenet\", \"../utils_imagenet.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose & load image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is based on a single test image of the ones stored in `examples/images`. Other example images can be used by loading these into the above folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the number of an image in the example folder (between 0-6)\n",
    "image_n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full list of currently available models is available at `/innvestigate/applications/imagenet.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose a list of models\n",
    "netnames = [\"vgg16\",\n",
    "            \"resnet50\",\n",
    "            \"inception_v3\"]\n",
    "\n",
    "n_nets = len(netnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse vgg15.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'innvestigate.applications.imagenet' has no attribute 'vgg15'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a1c69738abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Build model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnvestigate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpattern_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'innvestigate.applications.imagenet' has no attribute 'vgg15'"
     ]
    }
   ],
   "source": [
    "pattern_type = \"relu\"\n",
    "channels_first = keras.backend.image_data_format == \"channels_first\"\n",
    "analysis_all = []\n",
    "\n",
    "for i, netname in enumerate(netnames):\n",
    "    print(\"Analyse {}.\".format(netname))\n",
    "    \n",
    "    # Build model.\n",
    "    tmp = getattr(innvestigate.applications.imagenet, netname)\n",
    "    net = tmp(load_weights=True, load_patterns=pattern_type)\n",
    "    model = keras.models.Model(inputs=net[\"in\"], outputs=net[\"out\"])\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    modelp = keras.models.Model(inputs=net[\"in\"], outputs=net[\"sm_out\"])\n",
    "    modelp.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    \n",
    "    # Load image from example folder\n",
    "    images, label_to_class_name = eutils.get_imagenet_data(net[\"image_shape\"][0])\n",
    "    images = images[image_n]\n",
    "    label_to_class_name = label_to_class_name[image_n]\n",
    "    \n",
    "    color_conversion = \"BGRtoRGB\" if net[\"color_coding\"] == \"BGR\" else None\n",
    "\n",
    "    # Analysis.\n",
    "    patterns = net[\"patterns\"]\n",
    "        \n",
    "    methods = [\n",
    "        # NAME             POSTPROCESSING     TITLE\n",
    "\n",
    "        # Show input.\n",
    "        (\"input\",                 {},                            imgnetutils.image,   \"Input\"),\n",
    "\n",
    "        # Function\n",
    "        (\"gradient\",              {},                            imgnetutils.graymap, \"Gradient\"),\n",
    "        (\"integrated_gradients\",  {},                            imgnetutils.graymap, (\"Integrated\", \"Gradients\")),\n",
    "\n",
    "        # Signal\n",
    "        (\"deconvnet\",             {},                            imgnetutils.bk_proj, \"Deconvnet\"),\n",
    "        (\"guided_backprop\",       {},                            imgnetutils.bk_proj, (\"Guided\", \"Backprop\"),),\n",
    "        (\"pattern.net\",           {\"patterns\": patterns},        imgnetutils.bk_proj, \"PatterNet\"),\n",
    "\n",
    "        # Interaction\n",
    "        (\"pattern.attribution\",   {\"patterns\": patterns},        imgnetutils.heatmap, (\"Pattern\", \"Attribution\"),),\n",
    "        (\"lrp.epsilon\",           {},                            imgnetutils.heatmap, \"LRP Epsilon\"),\n",
    "        (\"lrp.composite_a\",       {},                            imgnetutils.heatmap, \"LRP CompositeA\"),\n",
    "        (\"lrp.composite_b\",       {},                            imgnetutils.heatmap, \"LRP CompositeB\")\n",
    "    ]\n",
    "\n",
    "    # Create analyzers.\n",
    "    analyzers = []\n",
    "    for method in methods:\n",
    "        try:\n",
    "            analyzer = innvestigate.create_analyzer(method[0],\n",
    "                                                      model,\n",
    "                                                      **method[1])\n",
    "        except innvestigate.NotAnalyzeableModelException:\n",
    "            analyzer = None\n",
    "        analyzers.append(analyzer)\n",
    "\n",
    "    # Create analysis.\n",
    "    analysis = np.zeros([len(analyzers)] + net[\"image_shape\"] + [3])\n",
    "\n",
    "    image,y = images\n",
    "    image = image[None, :, :, :]\n",
    "    # Predict label.\n",
    "    x = imgnetutils.preprocess(image, net)\n",
    "    presm = model.predict_on_batch(x)[0]\n",
    "    prob = modelp.predict_on_batch(x)[0]\n",
    "    y_hat = prob.argmax()\n",
    "\n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        # Measure execution time\n",
    "        t_start = time.time()\n",
    "        print('{} '.format(''.join(methods[aidx][-1])), end='', flush=True)\n",
    "        \n",
    "        is_input_analyzer = methods[aidx][0] == \"input\"\n",
    "        # Analyze.\n",
    "        if analyzer != None:\n",
    "            a = analyzer.analyze(image if is_input_analyzer else x)\n",
    "        else:\n",
    "            print(\"Analyzer not available for this model.\")\n",
    "        \n",
    "        t_elapsed = time.time() - t_start\n",
    "        print('({:.4f}s) '.format(t_elapsed), end='', flush=True)\n",
    "        \n",
    "        # Postprocess.\n",
    "        if not np.all(np.isfinite(a)):\n",
    "            print(\"Image %i, analysis of %s not finite: nan %s inf %s\" %\n",
    "                  (i, methods[aidx][3],\n",
    "                   np.any(np.isnan(a)), np.any(np.isinf(a))))\n",
    "        if not is_input_analyzer:\n",
    "            a = imgnetutils.postprocess(a, color_conversion, channels_first)\n",
    "        a = methods[aidx][2](a)\n",
    "        analysis[aidx] = a[0]\n",
    "        \n",
    "        if analyzer != None:\n",
    "            print('Finished analysis of {}'.format(''.join(methods[aidx][-1])))\n",
    "    \n",
    "    # Clear session.\n",
    "    if keras.backend.backend() == 'tensorflow':\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    analysis_all.append(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the analysis.\n",
    "grid = [[analysis_all[i][j] for j in range(len(methods))]\n",
    "        for i in range(n_nets)]\n",
    "row_labels = netnames\n",
    "col_labels = [method[3] for method in methods]\n",
    "\n",
    "n_rows = len(grid)\n",
    "n_cols = len(grid[0])\n",
    "shape_per_image = grid[0][0].shape[:2]\n",
    "n_padding = shape_per_image[0]//5\n",
    "shape_per_image_padded = [s + 2 * n_padding for s in shape_per_image]\n",
    "fontsize = 10\n",
    "\n",
    "plt.figure(figsize = (n_cols, n_rows))\n",
    "for r in range(n_rows):\n",
    "    for c in range(n_cols):\n",
    "        ax = plt.subplot2grid(shape=[n_rows, n_cols], loc=[r,c])\n",
    "        ax.imshow(grid[r][c], interpolation='none') \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        if not r: #method names\n",
    "            ax.set_title(col_labels[c],\n",
    "                         rotation=22.5,\n",
    "                         horizontalalignment='left',\n",
    "                         verticalalignment='bottom')\n",
    "        if not c: #network names\n",
    "            ax.set_ylabel(row_labels[r],\n",
    "                          rotation=0,\n",
    "                          verticalalignment='center',\n",
    "                          horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
