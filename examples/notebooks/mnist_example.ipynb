{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the use of the proposed in(n)vestigation methods on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.tests.networks.base\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "\n",
    "eutils = imp.load_source(\"utils\", \"../utils.py\")\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"../utils_mnist.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "channels_first = keras.backend.image_data_format == \"channels_first\"\n",
    "data = mnistutils.fetch_data(channels_first)\n",
    "num_classes = len(np.unique(data[1]))\n",
    "\n",
    "# Test samples for illustrations\n",
    "images = [(data[2][i].copy(), data[3][i]) for i in range(num_classes)]\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter\n",
    "zero_mean = False\n",
    "\n",
    "data_preprocessed = (mnistutils.preprocess(data[0],zero_mean), data[1],\n",
    "                     mnistutils.preprocess(data[2],zero_mean), data[3])  #TODO: change this!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create & train a Multilayer Perceptron with two fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.2208 - acc: 0.9338\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.0948 - acc: 0.9711\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.0681 - acc: 0.9781\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0498 - acc: 0.9842\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.0399 - acc: 0.9871\n",
      "Test loss: 0.08198731753372121\n",
      "Test accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "# Parameter\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "activation_type = \"relu\"\n",
    "\n",
    "# Create & train model\n",
    "model, modelp = mnistutils.create_model(channels_first, activation_type, num_classes)\n",
    "mnistutils.train_model(modelp, data_preprocessed, batch_size=batch_size, epochs=epochs)\n",
    "model.set_weights(modelp.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below specified methods to in(n)vestigate and visualize the learned classifier on a few example images. \n",
    "\n",
    "Hereby the analyse method containing name, optional parameter, postprocessing information and a title for the final visualisation is passed into the framework by a n-tuple. The available methods are subdivided into three groups depending on their principal approach: gradient-based, pattern-based and relevance-based investigation methods. For a full list of methods please refer to the script in `innvestigate/innvestigate/analyzer/__init__.py` or in the list below (available upon first release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Methods we use and some properties.\n",
    "methods = [\n",
    "    # NAME                                             POSTPROCESSING       TITLE\n",
    "\n",
    "    # Show input.\n",
    "    (\"input\",                 {},                       mnistutils.image,   \"Input\"),\n",
    "\n",
    "    # Function\n",
    "    (\"gradient\",              {},                       mnistutils.graymap, \"Gradient\"),\n",
    "    (\"smoothgrad\",            {\"noise_scale\": 50},      mnistutils.graymap, \"SmoothGrad\"),\n",
    "    (\"integrated_gradients\",  {},                       mnistutils.graymap, (\"Integrated\", \"Gradients\")),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                       mnistutils.bk_proj, \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                       mnistutils.bk_proj, (\"Guided\", \"Backprop\"),),\n",
    "    (\"pattern.net\",           {},                       mnistutils.bk_proj, \"PatterNet\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",   {},                       mnistutils.heatmap, \"Pattern\", \"Attribution\"),\n",
    "    (\"lrp.z\",                 {},                       mnistutils.heatmap, \"LRP\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "235/235 [==============================] - 18s 75ms/step - loss: 2.0000 - broadcast_1_loss: 1.0000 - broadcast_2_loss: 1.0000\n",
      "Epoch 1/1\n",
      "122/235 [==============>...............] - ETA: 8s - loss: 2.0000 - broadcast_3_loss: 1.0000 - broadcast_4_loss: 1.0000"
     ]
    }
   ],
   "source": [
    "# Create analyzers.\n",
    "\n",
    "pattern_type = activation_type\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    analyzer = innvestigate.create_analyzer(method[0],\n",
    "                                            model,\n",
    "                                            **method[1])\n",
    "    analyzer.fit(data_preprocessed[0], pattern_type=pattern_type,\n",
    "                 batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)\n",
    "\n",
    "# Create analysis.\n",
    "analysis = np.zeros([len(images), len(analyzers), 28, 28, 3])\n",
    "text = []\n",
    "for i, (image, y) in enumerate(images):\n",
    "    image = image[None, :, :, :]\n",
    "    # Predict label.\n",
    "    x = mnistutils.preprocess(image, zero_mean)\n",
    "    presm = model.predict_on_batch(x)[0]\n",
    "    prob = modelp.predict_on_batch(x)[0]\n",
    "    y_hat = prob.argmax()\n",
    "\n",
    "    text.append((\"%s\" %label_to_class_name[y], \"%.2f\" %presm.max(), \n",
    "                 \"%.2f\" % prob.max(), \"%s\" %label_to_class_name[y_hat]))\n",
    "\n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        is_input_analyzer = methods[aidx][0] == \"input\"\n",
    "        # Analyze.\n",
    "        a = analyzer.analyze(image if is_input_analyzer else x)\n",
    "        # Postprocess.\n",
    "        if not is_input_analyzer:\n",
    "            a = mnistutils.postprocess(a)\n",
    "        a = methods[aidx][2](a)\n",
    "        analysis[i, aidx] = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analysis.\n",
    "\n",
    "grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "        for i in range(analysis.shape[0])]\n",
    "row_labels = text\n",
    "col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "eutils.plot_image_grid(grid, row_labels, col_labels,\n",
    "                       file_name=None,\n",
    "                       row_label_offset=0,\n",
    "                       col_label_offset=0,\n",
    "                       is_fontsize_adaptive=True,\n",
    "                       usetex=False,\n",
    "                       dpi=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
