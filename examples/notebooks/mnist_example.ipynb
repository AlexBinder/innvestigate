{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how saliency maps are computed by various methods for smaller, not so massive neural networks based on the well-known `MNIST` data set. For a first glimpse onto the general workflow for using the *iNNvestigate* toolbox, or for users without access to beefy GPU or CPU hardware with tons of RAM, this is a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import imp\n",
    "import time\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "\n",
    "eutils = imp.load_source(\"utils\", \"../utils.py\")\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"../utils_mnist.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Then, the MNIST data is loaded in its entirety, formatted wrt to the specifications of the keras backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "channels_first = keras.backend.image_data_format() == \"channels_first\"\n",
    "data = mnistutils.fetch_data(channels_first) #returns x_train, y_train, x_test, y_test as numpy.ndarray\n",
    "num_classes = len(np.unique(data[1]))\n",
    "\n",
    "# Test samples for illustrations\n",
    "images = [(data[2][i].copy(), data[3][i]) for i in range(num_classes)]\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "We have prepared a simple model configuration to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack model params by name. The line below currently selects an already pretrained network, which saves some time.\n",
    "modelname = 'mlp_3dense'\n",
    "activation_type = 'relu'\n",
    "input_range = [-1, 1]\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "create_model_kwargs = {'dense_units':1024, 'dropout_rate':0.25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, preprocess the data wrt to the model's requirements, build the model and optionally train it for `epochs` epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3180 - acc: 0.9013\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1707 - acc: 0.9476\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1377 - acc: 0.9578\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1192 - acc: 0.9617\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1088 - acc: 0.9663\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0992 - acc: 0.9682\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0941 - acc: 0.9702\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0852 - acc: 0.9733\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0818 - acc: 0.9743\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0783 - acc: 0.9750\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0746 - acc: 0.9762\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0713 - acc: 0.9773\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0682 - acc: 0.9784\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0685 - acc: 0.9780\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0644 - acc: 0.9796\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0616 - acc: 0.9802\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0645 - acc: 0.9793\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0613 - acc: 0.9807\n",
      "Epoch 19/20\n",
      "48256/60000 [=======================>......] - ETA: 0s - loss: 0.0589 - acc: 0.9822"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "data_preprocessed = (mnistutils.preprocess(data[0], input_range), data[1],\n",
    "                     mnistutils.preprocess(data[2], input_range), data[3])\n",
    "\n",
    "\n",
    "# Create & (optionally) train model\n",
    "model, modelp = mnistutils.create_model(channels_first, modelname, **create_model_kwargs)\n",
    "mnistutils.train_model(modelp, data_preprocessed, batch_size=batch_size, epochs=epochs)\n",
    "model.set_weights(modelp.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set up a list of analysis methods by preparing tuples containing the methods' string identifiers used by `innvestigate.analyzer.create_analyzer(...)`, some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render. Analyzers can be deactivated by simply commenting the corresponding lines, or added by creating a new tuple as below.\n",
    "\n",
    "For a full list of methods refer to the dictionary `investigate.analyzer.analyzers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine analysis methods and properties\n",
    "methods = [\n",
    "    # NAME                    OPT.PARAMS               POSTPROC FXN                TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",                 {},                       mnistutils.image,          \"Input\"),\n",
    "\n",
    "    # Function\n",
    "    (\"gradient\",              {},                       mnistutils.graymap,        \"Gradient\"),\n",
    "    (\"smoothgrad\",            {\"noise_scale\": 50},      mnistutils.graymap,        \"SmoothGrad\"),\n",
    "    (\"integrated_gradients\",  {},                       mnistutils.graymap,        \"Integrated Gradients\"),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                       mnistutils.bk_proj,        \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                       mnistutils.bk_proj,        \"Guided Backprop\",),\n",
    "    (\"pattern.net\",           {},                       mnistutils.bk_proj,        \"PatternNet\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"lrp.z\",                 {},                       mnistutils.heatmap,         \"LRP-Z\"),\n",
    "    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,         \"LRP-Epsilon\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop below will now instantiate the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above and compute the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analyzers.\n",
    "analyzers = []\n",
    "print('Creating analyzer instances. ')\n",
    "for method in methods:\n",
    "    analyzer = innvestigate.create_analyzer(method[0],   # analysis method identifier\n",
    "                                            model,       # model without softmax output\n",
    "                                            **method[1]) # optional analysis parameters\n",
    "    # some analyzers require additional training. For those\n",
    "    analyzer.fit(data_preprocessed[0],\n",
    "                 pattern_type=activation_type,\n",
    "                 batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)\n",
    "\n",
    "print('Running analyses.')\n",
    "# Apply analyzers to trained model.\n",
    "analysis = np.zeros([len(images), len(analyzers), 28, 28, 3])\n",
    "text = []\n",
    "for i, (image, y) in enumerate(images):\n",
    "    print('Image {}: '.format(i), end='')\n",
    "    t_start = time.time()\n",
    "    image = image[None, :, :, :]\n",
    "    # Predict label.\n",
    "    x = mnistutils.preprocess(image, input_range)\n",
    "    presm = model.predict_on_batch(x)[0] #forward pass without softmax\n",
    "    prob = modelp.predict_on_batch(x)[0] #forward pass with softmax\n",
    "    y_hat = prob.argmax()\n",
    "    \n",
    "    # Save prediction info:\n",
    "    text.append((\"%s\" %label_to_class_name[y],    # ground truth label\n",
    "                 \"%.2f\" %presm.max(),             # pre-softmax logits\n",
    "                 \"%.2f\" %prob.max(),              # probabilistic softmax output  \n",
    "                 \"%s\" %label_to_class_name[y_hat] # predicted label\n",
    "                ))\n",
    "    \n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        # Measure execution time\n",
    "        \n",
    "        is_input_analyzer = methods[aidx][0] == \"input\"\n",
    "        # Analyze.\n",
    "        a = analyzer.analyze(image if is_input_analyzer else x)\n",
    "        \n",
    "        # Postprocess.\n",
    "        if not is_input_analyzer:\n",
    "            a = mnistutils.postprocess(a)\n",
    "        a = methods[aidx][2](a)\n",
    "        analysis[i, aidx] = a[0]\n",
    "    t_elapsed = time.time() - t_start\n",
    "    print('{:.4f}s'.format(t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that the analysis times for `Image 0` are substantially longer for all methods, compared to the follow-ups. Each analyzer manages a computational graph it attaches to the analyzed model. Upon first execution, the analyzer needs to build that graph, which can take some time. Each consecutive analysis on the same model though is almost instant.\n",
    "\n",
    "Next, we visualize the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analysis.\n",
    "grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "        for i in range(analysis.shape[0])]\n",
    "label, presm, prob, pred = zip(*text)\n",
    "row_labels_left = [('label: {}'.format(label[i]),'pred: {}'.format(pred[i])) for i in range(len(label))]\n",
    "row_labels_right = [('logit: {}'.format(presm[i]),'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This figure shows the analysis regarding the *actually predicted* class as computed by the selected analyzers. Each column shows the visualized results for different analyzers and each row shows the analyses wrt to one input sample. To the left of each row, the ground truth label `label` and the predicted label `pred` are show. To the right, the model's probabilistic (softmax) output is shown as `prob` and the logit output just before the terminating softmax layer as `logit`. Note that all analyses have been performed based on the logit output (layer).\n",
    "\n",
    "If you are curious about how *iNNvestigate* performs on ImageNet models and data, [go here.](imagenet_example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
