{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenet Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the use of the proposed in(n)vestigation methods on the ImageNet dataset for a pretrained VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import imp\n",
    "import keras.backend\n",
    "import keras.models\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.tests.networks.base\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "\n",
    "eutils = imp.load_source(\"utils\", \"../utils.py\")\n",
    "imgnetutils = imp.load_source(\"utils_imagenet\", \"../utils_imagenet.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a few (preselected) example images from the ImageNet dataset. In order to load your choice of images from the ImageNet dataset, place them into `innvestigate/examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get some example test set images.\n",
    "images, label_to_class_name = eutils.get_imagenet_data()[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained VGG16 net with ReLUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter\n",
    "netname = \"vgg16\"\n",
    "pattern_type = \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file './imagenet_224_vgg_16.pattern_file.A_only.npz' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '<'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-07ca77253e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minnvestigate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpattern_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate-0.1-py3.6.egg/innvestigate/applications/imagenet.py\u001b[0m in \u001b[0;36mvgg16\u001b[0;34m(load_weights, load_patterns)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mcolor_coding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BGR\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mload_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         load_patterns=load_patterns)\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate-0.1-py3.6.egg/innvestigate/applications/imagenet.py\u001b[0m in \u001b[0;36m_prepare_keras_net\u001b[0;34m(clazz, image_shape, preprocess_f, color_coding, load_weights, load_patterns)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Download the necessary parameters for VGG16 and the according patterns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne_weights_to_keras_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"patterns\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate-0.1-py3.6.egg/innvestigate/applications/imagenet.py\u001b[0m in \u001b[0;36mload_patterns\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 raise IOError(\n\u001b[0;32m--> 431\u001b[0;31m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to interpret file './imagenet_224_vgg_16.pattern_file.A_only.npz' as a pickle"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "channels_first = keras.backend.image_data_format == \"channels_first\"\n",
    "\n",
    "tmp = getattr(innvestigate.applications.imagenet, netname)\n",
    "net = tmp(load_weights=True, load_patterns=pattern_type)\n",
    "model = keras.models.Model(inputs=net[\"in\"], outputs=net[\"out\"])\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "modelp = keras.models.Model(inputs=net[\"in\"], outputs=net[\"sm_out\"])\n",
    "modelp.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use several methods to in(n)vestigate and visualize the learned classifier on the example images.\n",
    "\n",
    "Hereby the analyse method containing name, optional parameter, postprocessing information and a title for the final visualisation is passed into the framework by a n-tuple. The available methods are subdivided into three groups depending on their principal approach: gradient-based, pattern-based and relevance-based investigation methods. For a full list of methods please refer to the script in `innvestigate/innvestigate/analyzer/__init__.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_conversion = \"BGRtoRGB\" if net[\"color_coding\"] == \"BGR\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2178066087d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Analysis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"patterns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Methods we use and some properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m methods = [\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# Create list of in(n)vestigation methods we want to apply to the trained model, if applicable specify optional \n",
    "# parameters\n",
    "\n",
    "methods = [\n",
    "    # NAME             POSTPROCESSING     TITLE\n",
    "\n",
    "    # Show input.\n",
    "    (\"input\",                 {},                            imgnetutils.image,   \"Input\"),\n",
    "\n",
    "    # Function\n",
    "    (\"gradient\",              {},                            imgnetutils.graymap, \"Gradient\"),\n",
    "    (\"smoothgrad\",            {\"noise_scale\": 50},           imgnetutils.graymap, \"SmoothGrad\"),\n",
    "    (\"integrated_gradients\",  {},                            imgnetutils.graymap, (\"Integrated\", \"Gradients\")),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                            imgnetutils.bk_proj, \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                            imgnetutils.bk_proj, (\"Guided\", \"Backprop\"),),\n",
    "    (\"pattern.net\",           {\"patterns\": net[\"patterns\"]}, imgnetutils.bk_proj, \"PatterNet\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",   {\"patterns\": net[\"patterns\"]}, imgnetutils.heatmap, \"Pattern\", \"Attribution\"),\n",
    "    (\"lrp.z_baseline\",        {},                            imgnetutils.heatmap, \"LRP-Z\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create analyzers.\n",
    "analyzers = []\n",
    "print('Create analyzer for ', flush=True)\n",
    "for method in methods:\n",
    "    print('{} '.format(''.join(method[3])), flush=True)\n",
    "    analyzers.append(innvestigate.create_analyzer(method[0], \n",
    "                                                  model, \n",
    "                                                  **method[1]))\n",
    "\n",
    "# Apply analyzers to trained VGG model.\n",
    "analysis = np.zeros([len(images), len(analyzers), 224, 224, 3])\n",
    "text = []\n",
    "for i, (image, y) in enumerate(images):\n",
    "    image = image[None, :, :, :]\n",
    "    # Predict label.\n",
    "    x = preprocess(image)\n",
    "    presm = model.predict_on_batch(x)[0]\n",
    "    prob = modelp.predict_on_batch(x)[0]\n",
    "    y_hat = prob.argmax()\n",
    "\n",
    "   # Save label, pre-softmax activation, probabilistic output and predicted label for plots\n",
    "    text.append((\"%s\" %label_to_class_name[y], \"%.2f\" %presm.max(), \n",
    "                 \"%.2f\" % prob.max(), \"%s\" %label_to_class_name[y_hat]))\n",
    "    \n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "        # Measure execution time\n",
    "        t_start = time.time()\n",
    "        print('{} '.format(''.join(methods[aidx][-1])), end='', flush=True)\n",
    "        \n",
    "        is_input_analyzer = methods[aidx][0] == \"input\"\n",
    "        # Analyze.\n",
    "        a = analyzer.analyze(image if is_input_analyzer else x)\n",
    "        \n",
    "        t_elapsed = time.time() - t_start\n",
    "        print('({:.4f}s) '.format(t_elapsed), end='', flush=True)\n",
    "        \n",
    "        # Postprocess.\n",
    "        if not np.all(np.isfinite(a)):\n",
    "            print(\"Image %i, analysis of %s not finite: nan %s inf %s\" %\n",
    "                  (i, methods[aidx][3],\n",
    "                   np.any(np.isnan(a)), np.any(np.isinf(a))))\n",
    "        if not is_input_analyzer:\n",
    "            a = postprocess(a)\n",
    "        a = methods[aidx][2](a)\n",
    "        analysis[i, aidx] = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analysis.\n",
    "\n",
    "grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "        for i in range(analysis.shape[0])]  \n",
    "row_labels = text\n",
    "col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "eutils.plot_image_grid(grid, row_labels, col_labels,\n",
    "                       filename=None,\n",
    "                       row_label_offset=0,\n",
    "                       col_label_offset=0,\n",
    "                       is_fontsize_adaptive=False,\n",
    "                       usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
