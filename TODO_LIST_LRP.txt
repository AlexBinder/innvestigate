

2) (redacted) Refactor ReverseLayer and all dependencies as independent classes (not possible without major rework/deviation from the major class structure for all analyzer classes)
2.1) Ensure ReverseLayer works for layers without kernels (some LRP methods will make no sense/are the same, others do.)
2.1.1) BatchNormalization
2.1.2) Merge type layers
2.1.3) Add type layers
2.1.4) Nonlinearities and activation layers (handle non-zero-centered fxns. they break things)
2.1.5) Poolling type layers (Flat decomp might be desirable here. Need ReverseLayer subclass)

3) allow conditioned rule mappings to depend on layer index, e.g. for selecting layers for FlatRule
4) allow selection class to LRP-decompose based on class index #TODO: write issue: implement fxn go over keras graph and return a list of layers so the indexing of layers is known/correct
5) numerical testing for supported layers # TODO: issue describing what needs to exist
6) ipython notebooks showing analyzer setup and influence of parameters

